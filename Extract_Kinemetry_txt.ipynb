{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collab\n",
      "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE1Njg4MzIzMzIsIm5iZiI6MTU2ODgzMjMzMiwianRpIjoiNGYzMWIyM2MtYTRmYS00MDhiLTg1OWMtOTAyNGI1ZTc0MjY3IiwiZXhwIjoxNTk0NzUyMzMyLCJpZGVudGl0eSI6InNkc3MiLCJmcmVzaCI6dHJ1ZSwidHlwZSI6ImFjY2VzcyJ9.dn2rQ5xk38hBmp-djVfOhQSX1khVKAQrzarvNOkPjJ0\n",
      "SDSS_ACCESS> syncing... please wait\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Go to Marvin Github and import some tutorial stuff\n",
    "from marvin.tools.maps import Maps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import marvin\n",
    "from marvin import config, marvindb\n",
    "import math\n",
    "from bresenham import bresenham\n",
    "import numpy.ma as ma\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import asarray as ar,exp\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "# Make sure you have collaborator access - if not go set it up following these instructinos:\n",
    "# https://sdss-marvin.readthedocs.io/en/stable/installation.html\n",
    "config.access = 'collab'\n",
    "# Choose the data release you would like to use (could also use MPL)\n",
    "config.setRelease('MPL-8')\n",
    "print(config.access)\n",
    "\n",
    "# I had to re-log in when I first ran this code:\n",
    "config.login(refresh=True)\n",
    "print(config.token)\n",
    "\n",
    "#Strong bars:\n",
    "#8444-12703\n",
    "#8984-12704\n",
    "#8135-6103\n",
    "#9196-12701\n",
    "#9886-12705\n",
    "\n",
    "#Weak bars (some of these might not have enough signal to do anything with their velocity fields. Let me know if so and I’ll find some others):\n",
    "#8987-12702\n",
    "#8567-12703\n",
    "#8318-12704\n",
    "#8988-12705\n",
    "#8332-12701\n",
    "\n",
    "# Check to see if this map loads remotely, if so you are good to go- \n",
    "plateids = ['8332-12701']# this is my favorite galaxy\n",
    "Maps(plateids[0]).download()\n",
    "\n",
    "maps = [Maps(plateid) for plateid in plateids]\n",
    "# .datamodel shows all the options for various map extensions\n",
    "#print(Maps('7443-12703').datamodel)\n",
    "\n",
    "print(maps[0].header['REFF'], 'Reff')\n",
    "print(maps[0].header['ECOOELL'], 'ellipticity')\n",
    "print(maps[0].header['ECOOPA'], 'PA')\n",
    "\n",
    "\n",
    "\n",
    "svel_maps = [mapz['stellar_vel'].value for mapz in maps]# this is in case you want to feed it a list\n",
    "svel_map = svel_maps[0]\n",
    "svel_map = ma.masked_where(svel_map==0, svel_map)\n",
    "\n",
    "svel_e_maps = [1/np.sqrt(mapz['stellar_vel'].ivar) for mapz in maps]# this is in case you want to feed it a list\n",
    "svel_e_map = svel_e_maps[0]\n",
    "\n",
    "# sigma_star_corr = sqrt( STELLAR_SIGMA2 - STELLAR_SIGMACORR2 )\n",
    "ssig_maps = [np.sqrt(mapz['stellar_sigma'].value**2-mapz['stellar_sigmacorr'].value**2) for mapz in maps]# this is in case you want to feed it a list\n",
    "ssig_map = ssig_maps[0]\n",
    "ssig_map = ma.masked_where(ssig_map==0, ssig_map)\n",
    "\n",
    "\n",
    "ssig_e_maps = [1/np.sqrt(mapz['stellar_sigma'].ivar) for mapz in maps]# this is in case you want to feed it a list\n",
    "ssig_e_map = ssig_e_maps[0]\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(svel_map, cmap='RdBu_r')\n",
    "plt.title(r'$V_*$')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(svel_e_map, cmap='RdBu_r')\n",
    "plt.title(r'Error $V_*$')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(ssig_map, vmax=200, cmap='plasma')\n",
    "plt.title(r'$\\sigma_*$')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(ssig_e_map,vmax=200, cmap='plasma')\n",
    "plt.title(r'Error $\\sigma_*$')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSTILL TO DO AND THIS IS HUGE - \\nYOU NEED TO CHECK THE MANGA IMAGING PARAMETERS LIKE R_EFF AND ELLIPTICITY AGAINST THOSE YOU DERIVE\\nFROM YOUR IMAGING PIPELINE.\\n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "STILL TO DO AND THIS IS HUGE - \n",
    "YOU NEED TO CHECK THE MANGA IMAGING PARAMETERS LIKE R_EFF AND ELLIPTICITY AGAINST THOSE YOU DERIVE\n",
    "FROM YOUR IMAGING PIPELINE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(svel_map))\n",
    "\n",
    "\n",
    "\n",
    "# First get effective radius, PA, and ellipticity from MaNGA, then run GALFIT on em\n",
    "\n",
    "#ECOOPA\tPosition angle used for the semi-major axis polar coordinate calculations\n",
    "#ECOOELL\tEllipticity (1-b/a) used for the semi-major axis polar coordinate calculations\n",
    "\n",
    "R_e_MaNGA = maps[0].header['REFF']\n",
    "ellip_MaNGA = maps[0].header['ECOOELL']\n",
    "PA_MaNGA = maps[0].header['ECOOPA']\n",
    "\n",
    "\n",
    "'''img_params=extract_GALFIT_parameters(view, myr, im, run)\n",
    "#return PA_img, size_a, arcs_totes, inc, pixelscale, r_e\n",
    "if img_params[0]==0:#this means the GALFIT file doesn't exist\n",
    "    STOP\n",
    "#    continue\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    #I have found the PA from GALFIT to be better than the PA from statmorph \n",
    "    #which is commented out below\n",
    "    PA_imag=img_params[0]\n",
    "except TypeError:\n",
    "     STOP'''\n",
    "#   continue\n",
    "\n",
    "\n",
    "epsilon = ellip_MaNGA#1-img_params[1]\n",
    "r_e = R_e_MaNGA#img_params[2]\n",
    "\n",
    "#print('deltapos', deltapos)\n",
    "#continue\n",
    "\n",
    "#epsilon = float(kin_cube[0].header['ellip']), again the epsilon from GALFIT is better\n",
    "#r_e = float(kin_cube[0].header['REFF'])\n",
    "#PA_img = float(kin_cube[0].header['PA_img']), again, the PA from GALFIT seems to be better\n",
    "\n",
    "#axial ratio (q) = b/a = semi-minor/semi-major\n",
    "#ellipticity (ε) = 1 – q\n",
    "\n",
    "\n",
    "\n",
    "#from the r-band image you need to run statmorph and get both the ellipticity and the r-band effective radius\n",
    "#we already measured this from the r-band image in the kinematic program so I'd like to extract those two \n",
    "#parameters from the header of the stellar_kinematics file\n",
    "\n",
    "\n",
    "\n",
    "size=np.shape(svel_map)[0]\n",
    "\n",
    "# Prepare kin_cube, which has four dimensions - vel, vel_e, sig, and sig_e\n",
    "\n",
    "kin_cube=[[svel_map],[svel_e_map],[ssig_map],[ssig_e_map]]\n",
    "coords=map_to_coords(kin_cube, size)\n",
    "\n",
    "rad = radon_python_mod(svel_map, 30, 30, r_e, 1, 'yes', 'no')#was 30,30\n",
    "if rad[8]==1:#this means we gotta expand the grid\n",
    "    rad = radon_python_mod(vel, 30, 30, r_e, 2, 'no')\n",
    "\n",
    "\n",
    "\n",
    "input_kinemetry(plateids[0], coords[0], coords[1], coords[2], coords[3], coords[4], coords[5] , size/2-rad[0][1], size/2-rad[0][0],  'no', size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n"
     ]
    }
   ],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return array[idx]\n",
    "def gauss(x,a,x0,sigma,offset):\n",
    "    return a*exp(-(x-x0)**2/(2*sigma**2))+offset\n",
    "\n",
    "def ndim_grid(start,stop):\n",
    "    # Set number of dimensions\n",
    "    ndims = len(start)\n",
    "\n",
    "    # List of ranges across all dimensions\n",
    "    L = [np.arange(start[i],stop[i]) for i in range(ndims)]\n",
    "\n",
    "    # Finally use meshgrid to form all combinations corresponding to all \n",
    "    # dimensions and stack them as M x ndims array\n",
    "    return np.hstack((np.meshgrid(*L))).swapaxes(0,1).reshape(ndims,-1).T\n",
    "\n",
    "\n",
    "\n",
    "def extract_GALFIT_parameters(view, myr, im, run):\n",
    "    \"\"\"\n",
    "    This retrives the GALFIT predictors \n",
    "    \"\"\"\n",
    "    output='../LAURA_Sims/GALFIT_folder/out_'+str(run)+'_'+str(view)+'_'+str(myr)+'.fits'\n",
    "    try:\n",
    "        out=pyfits.open(output)\n",
    "    except FileNotFoundError:\n",
    "        #print('NO GALFIT FILEEEE')\n",
    "        STOP\n",
    "        \n",
    "        return 0, 0, 0\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            attempt=float(out[2].header['1_MAG'][0:5])\n",
    "            attempt_2=float(out[2].header['2_MAG'][0:5])\n",
    "        except ValueError:\n",
    "            return 0, 0, 0\n",
    "        if float(out[2].header['1_MAG'][0:5]) < float(out[2].header['2_MAG'][0:5]):\n",
    "        #this means the 1st one is brighter\n",
    "            inc=float(out[2].header['1_AR'][0:5])\n",
    "            r_e=float(out[2].header['1_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['1_PA'][:5]))\n",
    "            \n",
    "        else:\n",
    "            inc=float(out[2].header['2_AR'][0:5])\n",
    "            r_e=float(out[2].header['2_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['2_PA'][:5]))\n",
    "            \n",
    "    except KeyError or ValueError:#if there is no #2\n",
    "        try:\n",
    "            \n",
    "            inc=float(out[2].header['1_AR'][0:5])\n",
    "            r_e=float(out[2].header['1_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['1_PA'][:5]))\n",
    "        except ValueError:\n",
    "            return 0, 0, 0\n",
    "        \n",
    "    return PA_img, inc, r_e\n",
    "\n",
    "def map_to_coords(map_cube, size):\n",
    "    \"\"\"\n",
    "    Converts coordinates to list form (in order to feed through kinemetry).\n",
    "    \"\"\"\n",
    "    x_list=[]\n",
    "    y_list=[]\n",
    "    vel_list=[]\n",
    "    vel_e_list=[]\n",
    "    sig_list=[]\n",
    "    sig_e_list=[]\n",
    "    \n",
    "    vel_dimension=np.reshape(map_cube[0],(size,size))\n",
    "\n",
    "    vel_e_dimension=np.reshape(map_cube[1],(size,size))\n",
    "    sig_dimension=np.reshape(map_cube[2],(size,size))\n",
    "    sig_e_dimension=np.reshape(map_cube[3],(size,size))\n",
    "    \n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            try:\n",
    "                value = vel_dimension[i,j]\n",
    "                if str(value) == '--':\n",
    "                    continue\n",
    "                vel_list.append(vel_dimension[i,j])\n",
    "                x_list.append(i)\n",
    "                y_list.append(j)\n",
    "                vel_e_list.append(vel_e_dimension[i,j])\n",
    "                sig_list.append(sig_dimension[i,j])\n",
    "                sig_e_list.append(sig_e_dimension[i,j])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "    \n",
    "    \n",
    "    return x_list, y_list, vel_list, vel_e_list, sig_list, sig_e_list\n",
    "\n",
    "\n",
    "def radon_python_mod(vel_field, n_p, n_theta, r_ap, factor, plot, trouble):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This section performs the radon transform, from Stark et al. 2018.\n",
    "    \n",
    "    It is a long calculation, because it first calculates the Absolute Radon Transform (R_AB) of the velocity field, \n",
    "    then it iterates for multiple choices of the kinematic center. It determines the kinematic center by minimizing\n",
    "    the asymmetry, A, of the Radon profile calculated from R_AB using a centroiding method.\n",
    "    \n",
    "    If the kinematic center is on the edge of the search grid of spaxels, it throws a flag and the code will rerun\n",
    "    this function after expanding the grid.\n",
    "    \n",
    "    \"\"\"\n",
    "    #It first converts the x and y coordinates into p and theta coordinates (circular)\n",
    "    #p is rho, which is the distance of the point on the velocity field from the kinematic center\n",
    "    p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5,int(np.shape(vel_field)[0]/2)-5, int(np.shape(vel_field)[0]/2)+1)#was 5\n",
    "    p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5, int(np.shape(vel_field)[0]/2)-5,n_p)#was 20\n",
    "   \n",
    "    #theta is the angle from the negative y axis CCW to the point on the velocity map.\n",
    "    theta_list = np.linspace(0, 180, n_theta)#was 10\n",
    "    \n",
    "    #It searches over a grid of coordinates around the photometric center to find the 'kinematic center',\n",
    "    #so it creates a 3x3 grid (from -3 to 3 including 0) in 2D\n",
    "    box_list=list(ndim_grid([-3, -3],[4,4]))\n",
    "    #If the kinematic center is not found on the first iteration, it expands the dimensions of the grid\n",
    "    #by a factor of 2 upon rerunning.\n",
    "    box_list=[factor*x for x in box_list]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Here I create a X and Y meshgrid type list of these points, since this is a rough approximation of the \n",
    "    #full grid of points in order to later plot what is happening.\n",
    "    X_list=[]\n",
    "    Y_list=[]\n",
    "\n",
    "    for j in range(len(box_list)):\n",
    "\n",
    "        X_list.append(int(np.shape(vel_field)[0]/2+box_list[j][0]))#-10+box_list[b][0])\n",
    "        Y_list.append(int(np.shape(vel_field)[1]/2+box_list[j][1]))#-10+box_list[b][1])\n",
    "        \n",
    "    #print('X_list', X_list)\n",
    "    #print('Y_list', Y_list)\n",
    "    \n",
    "    #creates empty lists that will be populated with R_AB, and all other derived quantities from this for every \n",
    "    #rho, theta point.\n",
    "    A_list=[]\n",
    "    A_e_list=[]\n",
    "    A_2_list=[]\n",
    "    R_AB_list=[]\n",
    "    theta_hat_list=[]\n",
    "    theta_hat_e_list=[]\n",
    "    \n",
    "    \n",
    "    #First run it for just the center one, index b=24 in order to normalize relative to the center\n",
    "    #later on in the calculation of A.\n",
    "    R_AB=[]\n",
    "    b=24\n",
    "    \n",
    "    for i in range(len(p_list)):\n",
    "        for j in range(len(theta_list)):\n",
    "            #\n",
    "            X = int(p_list[i]*math.cos(math.radians(theta_list[j]))+np.shape(vel_field)[0]/2-0.5+box_list[b][0])#-10+box_list[b][0])\n",
    "            Y = int(p_list[i]*math.sin(math.radians(theta_list[j]))+np.shape(vel_field)[1]/2-0.5+box_list[b][1])#-10+box_list[b][1])\n",
    "            \n",
    "\n",
    "            '''We have an X and a Y and a theta (slope) so we should be able to get the intercept'''\n",
    "            '''And then two more points on either end'''\n",
    "\n",
    "\n",
    "            '''But we only want to calculate for things that are on the circle'''\n",
    "\n",
    "            try:\n",
    "                #if this point exists in the velocity field then you can continue\n",
    "                test_value = vel_field[X,Y]\n",
    "            except IndexError:\n",
    "                R_AB.append(-1000)\n",
    "                continue\n",
    "            if np.isnan(vel_field[X,Y]):\n",
    "                R_AB.append(-1000)\n",
    "                STOP2\n",
    "                continue\n",
    "\n",
    "            if str(vel_field[X,Y]) == '--':\n",
    "                R_AB.append(-1000)\n",
    "                continue\n",
    "            #calculate the slope of the line segment from the kinematic center (in this case the photometric center)\n",
    "            #to the given point\n",
    "            deltay = Y - np.shape(vel_field)[1]/2\n",
    "            deltax = X - np.shape(vel_field)[0]/2\n",
    "            #draw a line perpendicular to this; the radon transform will be calculated along this line\n",
    "            slope_p = math.tan(math.radians(theta_list[j]+90))#-deltax/deltay\n",
    "            #draw a line from the point to where it intersects the bottom left of the map, which is the new origin\n",
    "            intercept = Y - slope_p*X\n",
    "\n",
    "\n",
    "\n",
    "            if slope_p > 1000:\n",
    "                #vertical, so calculate along one value of X for the entire length of y\n",
    "                x_min = X\n",
    "                x_max = X\n",
    "                y_min = 0\n",
    "                y_max = np.shape(vel_field)[0]\n",
    "            else:\n",
    "                x_min = 0\n",
    "                x_max = np.shape(vel_field)[0]\n",
    "                y_min = intercept\n",
    "                y_max = intercept+slope_p*x_max\n",
    "\n",
    "            #This neat line draws a line through a given set of coordinates\n",
    "            bres_list = list(bresenham(int(x_min), int(y_min), int(x_max), int(y_max)))\n",
    "\n",
    "            #to calculate the absolute Bounded Radon Transform, do this for all points that are within r_e/2 of the center\n",
    "            #of the line:\n",
    "            vel_append=[]\n",
    "            for k in range(len(bres_list)):\n",
    "                if bres_list[k][0] < 0 or bres_list[k][1] < 0:\n",
    "                    continue\n",
    "                if np.sqrt((bres_list[k][0]-X)**2+(bres_list[k][1]-Y)**2) > r_e/2:\n",
    "                    continue\n",
    "               \n",
    "                try:\n",
    "                    vel_append.append(vel_field[bres_list[k][1], bres_list[k][0]])\n",
    "                    \n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "            #clean it up, no masked values in here!\n",
    "            vel_append_clean=[]\n",
    "            for k in range(len(vel_append)):\n",
    "                if ma.is_masked(vel_append[k]):\n",
    "                    continue\n",
    "                else:\n",
    "                    vel_append_clean.append(vel_append[k])\n",
    "\n",
    "\n",
    "            #finally, create R_AB by summing all of these velocity differences\n",
    "            if vel_append_clean:\n",
    "                inside=vel_append_clean-np.mean(vel_append_clean)\n",
    "                R_AB.append(np.sum(np.abs(inside)))\n",
    "            else:\n",
    "                R_AB.append(-1000)\n",
    "\n",
    "\n",
    "    R_AB=ma.masked_where(np.isnan(R_AB), R_AB)\n",
    "    R_AB = ma.masked_where(R_AB==-1000, R_AB)\n",
    "\n",
    "    \n",
    "    R_AB_array = np.reshape(R_AB, (len(p_list),len(theta_list)))\n",
    "\n",
    "    \n",
    "    '''Try to plot R_AB values'''\n",
    "    plt.clf()\n",
    "    plt.imshow(R_AB_array)\n",
    "    locs, labels = plt.yticks()\n",
    "    #p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5, int(np.shape(vel_field)[0]/2)-5,n_p)#was 20\n",
    "   \n",
    "    ylabels = [p_list[0], 0, p_list[-1]]\n",
    "    ylocs = [locs[0], locs[-1]/2, locs[-1]] \n",
    "    plt.yticks(ylocs, ylabels)\n",
    "    \n",
    "    locs, labels = plt.xticks()\n",
    "    #p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5, int(np.shape(vel_field)[0]/2)-5,n_p)#was 20\n",
    "   \n",
    "    xlabels = [theta_list[0], theta_list[-1]/2, theta_list[-1]]\n",
    "    xlocs = [locs[0], locs[-1]/2, locs[-1]] \n",
    "    plt.xticks(xlocs, xlabels)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    #Now, extract the R_AB value at each rho value across all theta values.\n",
    "    #This creates the Radon profile; the estimated value of theta hat that minimizes R_AB at each value of rho.\n",
    "    #We minimize R_AB because we want the theta value at each rho that \n",
    "\n",
    "    #these are the estimated values of theta that are best fit for a value of rho\n",
    "    theta_hat=[]\n",
    "    theta_hat_e=[]\n",
    "\n",
    "    for l in range(len(p_list)):\n",
    "\n",
    "        marginalized = R_AB_array[l,:]\n",
    "        marginalized = ma.masked_where(marginalized<1e-4, marginalized)\n",
    "        count = len([i for i in marginalized if i > 1e-3])\n",
    "        #count up how many elements are in the row of R_AB --> if it is less than 6, don't measure it\n",
    "        #because it will cause an error when trying to fit a Gaussian, k = n+1\n",
    "        if count < 6:\n",
    "            theta_hat.append(0)\n",
    "            theta_hat_e.append(0)\n",
    "            continue\n",
    "\n",
    "        if ma.is_masked(marginalized)==True:\n",
    "            theta_hat.append(0)\n",
    "            theta_hat_e.append(0)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            #initially, try to fit a negative gaussian to determine theta hat\n",
    "            popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(np.min(marginalized))],20,np.mean(marginalized)])\n",
    "            append_value = popt[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "        except RuntimeError or OptimizeError: \n",
    "            theta_hat.append(0)\n",
    "            theta_hat_e.append(0)\n",
    "\n",
    "            continue\n",
    "            \n",
    "            \n",
    "\n",
    "        #if the code fits a positive Gaussian, try a new guess for the correct theta hat, the second smallest value       \n",
    "        if (popt[0]>0):\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(sorted(marginalized)[1])],20,np.mean(marginalized)])\n",
    "                append_value = popt[1]\n",
    "                if popt[0] > 0:\n",
    "                    #if this doesn't work, quit and move on\n",
    "\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "            except RuntimeError or OptimizeError :\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "\n",
    "                continue\n",
    "        \n",
    "        #sometimes, it is necessary to shift the xs because the peak is at 180, which is right at the edge\n",
    "        if ((popt[1] - 3*np.sqrt(pcov[1][1])) < 0) or ((popt[1] + 3*np.sqrt(pcov[1][1])) > 180):\n",
    "            theta_list_shifted = theta_list+find_nearest(theta_list,90)\n",
    "            index_1 = list(theta_list).index(find_nearest(theta_list,90))\n",
    "            new_marginalized = np.concatenate((marginalized[index_1:], marginalized[:index_1]))\n",
    "\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list_shifted,new_marginalized,p0=[-abs(np.min(new_marginalized)-np.max(new_marginalized)),theta_list_shifted[list(new_marginalized).index(np.min(new_marginalized))],20,np.mean(new_marginalized)])\n",
    "                \n",
    "\n",
    "                if popt[0] > 0:\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "                if popt[1] > 180:\n",
    "                    append_value = popt[1]-180\n",
    "                else:\n",
    "                    append_value = popt[1]\n",
    "\n",
    "            except RuntimeError or OptimizeError :\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "\n",
    "                continue\n",
    "            \n",
    "        theta_hat.append(append_value)\n",
    "        theta_hat_e.append(np.sqrt(pcov[1][1]))\n",
    "\n",
    "    if trouble=='yes':\n",
    "        plt.clf()\n",
    "        plt.scatter(p_list, theta_hat)\n",
    "        plt.errorbar(p_list, theta_hat, yerr=theta_hat_e)\n",
    "        plt.show()\n",
    "        \n",
    "    #now to calculate A, it is necessary to sum the values of theta hat at a mirror image of themselves\n",
    "    #across p=0\n",
    "    delta_theta_sum=[]\n",
    "    delta_theta_sum_e=[]\n",
    "\n",
    "\n",
    "    for l in range(int(len(p_list)/2)):\n",
    "        if (theta_hat[0+l]==0) or (theta_hat[-1-l]==0) or (abs(theta_hat[0+l])>180) or (abs(theta_hat[-1-l]) > 180):\n",
    "\n",
    "            delta_theta_sum.append(0)\n",
    "            delta_theta_sum_e.append(0)\n",
    "        else:\n",
    "            if abs(theta_hat[0+l]-theta_hat[-1-l]) > 90:\n",
    "                #because the maximum you can be apart is 90\n",
    "                inside = 180 - abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "            else:\n",
    "                inside = abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "\n",
    "            delta_theta_sum.append(inside)\n",
    "            #I would also like to have an error estimate on this quantity:\n",
    "            delta_theta_sum_e.append(np.sqrt((theta_hat_e[0+l])**2+\n",
    "                                         (theta_hat_e[-1-l])**2))\n",
    "    \n",
    "\n",
    "\n",
    "    delta_theta_sum_masked=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "\n",
    "    \n",
    "\n",
    "    OG_weight=ma.count(delta_theta_sum_masked)\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax0 = fig.add_subplot(111)\n",
    "    if plot=='yes':\n",
    "        \n",
    "        im0 = ax0.imshow(vel_field, cmap='RdBu_r')\n",
    "    \n",
    "    \n",
    "    #Okay now do this for all the other positions in box_list\n",
    "    A_list=[]\n",
    "    A_e_list=[]\n",
    "    \n",
    "    A_2_list=[]\n",
    "    R_AB_list=[]\n",
    "    theta_hat_list=[]\n",
    "    theta_hat_e_list=[]\n",
    "\n",
    "    \n",
    "            \n",
    "    A_list=[]\n",
    "    A_e_list=[]\n",
    "    A_2_list=[]\n",
    "    R_AB_list=[]\n",
    "    theta_hat_list=[]\n",
    "    theta_hat_e_list=[]\n",
    "    \n",
    "    X_list_real=[]\n",
    "    Y_list_real=[]\n",
    "    \n",
    "\n",
    "    for b in range(len(box_list)):\n",
    "        R_AB=[]\n",
    "        X_list_real.append(np.shape(vel_field)[0]/2-0.5+box_list[b][0])\n",
    "        Y_list_real.append(np.shape(vel_field)[1]/2-0.5+box_list[b][1])\n",
    "        for i in range(len(p_list)):\n",
    "            for j in range(len(theta_list)):\n",
    "                #\n",
    "                X = int(p_list[i]*math.cos(math.radians(theta_list[j]))+np.shape(vel_field)[0]/2-0.5+box_list[b][0])#-10+box_list[b][0])\n",
    "                Y = int(p_list[i]*math.sin(math.radians(theta_list[j]))+np.shape(vel_field)[1]/2-0.5+box_list[b][1])#-10+box_list[b][1])\n",
    "                \n",
    "                try:\n",
    "                    #if this point exists in the velocity field then you can continue\n",
    "                    test_value = vel_field[X,Y]\n",
    "                except IndexError:\n",
    "                    R_AB.append(-1000)\n",
    "                    continue\n",
    "                if np.isnan(vel_field[X,Y]):\n",
    "                    R_AB.append(-1000)\n",
    "                    STOP2\n",
    "                    continue\n",
    "\n",
    "                if str(vel_field[X,Y]) == '--':\n",
    "                    R_AB.append(-1000)\n",
    "                    continue\n",
    "                #calculate the slope of the line segment from the kinematic center (in this case the photometric center)\n",
    "                #to the given point\n",
    "                deltay = Y - np.shape(vel_field)[1]/2\n",
    "                deltax = X - np.shape(vel_field)[0]/2\n",
    "                #draw a line perpendicular to this; the radon transform will be calculated along this line\n",
    "                slope_p = math.tan(math.radians(theta_list[j]+90))#-deltax/deltay\n",
    "                #draw a line from the point to where it intersects the bottom left of the map, which is the new origin\n",
    "                intercept = Y - slope_p*X\n",
    "\n",
    "\n",
    "\n",
    "                if slope_p > 1000:\n",
    "                    #vertical, so calculate along one value of X for the entire length of y\n",
    "                    x_min = X\n",
    "                    x_max = X\n",
    "                    y_min = 0\n",
    "                    y_max = np.shape(vel_field)[0]\n",
    "                else:\n",
    "                    x_min = 0\n",
    "                    x_max = np.shape(vel_field)[0]\n",
    "                    y_min = intercept\n",
    "                    y_max = intercept+slope_p*x_max\n",
    "\n",
    "                #This neat line draws a line through a given set of coordinates\n",
    "                bres_list = list(bresenham(int(x_min), int(y_min), int(x_max), int(y_max)))\n",
    "\n",
    "                \n",
    "                #to calculate the absolute Bounded Radon Transform, do this for all points that are within r_e/2 of the center\n",
    "                #of the line:\n",
    "                vel_append=[]\n",
    "                for k in range(len(bres_list)):\n",
    "                    if bres_list[k][0] < 0 or bres_list[k][1] < 0:\n",
    "                        continue\n",
    "                    if np.sqrt((bres_list[k][0]-X)**2+(bres_list[k][1]-Y)**2) > r_e/2:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        vel_append.append(vel_field[bres_list[k][1], bres_list[k][0]])\n",
    "                        #vel_new[bres_list[j][1], bres_list[j][0]] = vel_field[bres_list[j][1], bres_list[j][0]]\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "\n",
    "                #clean it up, no masked values in here!\n",
    "                vel_append_clean=[]\n",
    "                for k in range(len(vel_append)):\n",
    "                    if ma.is_masked(vel_append[k]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        vel_append_clean.append(vel_append[k])\n",
    "\n",
    "\n",
    "                #finally, create R_AB by summing all of these velocity differences\n",
    "                if vel_append_clean:\n",
    "                    inside=vel_append_clean-np.mean(vel_append_clean)\n",
    "                    R_AB.append(np.sum(np.abs(inside)))\n",
    "                else:\n",
    "                    R_AB.append(-1000)\n",
    "\n",
    "\n",
    "        R_AB=ma.masked_where(np.isnan(R_AB), R_AB)\n",
    "        R_AB = ma.masked_where(R_AB==-1000, R_AB)\n",
    "\n",
    "\n",
    "        R_AB_array = np.reshape(R_AB, (len(p_list),len(theta_list)))\n",
    "\n",
    "\n",
    "        #Now, extract the R_AB value at each rho value across all theta values.\n",
    "        #This creates the Radon profile; the estimated value of theta hat that minimizes R_AB at each value of rho.\n",
    "        #We minimize R_AB because we want the theta value at each rho that \n",
    "\n",
    "        #these are the estimated values of theta that are best fit for a value of rho\n",
    "        theta_hat=[]\n",
    "        theta_hat_e=[]\n",
    "\n",
    "        for l in range(len(p_list)):\n",
    "\n",
    "            marginalized = R_AB_array[l,:]\n",
    "            marginalized = ma.masked_where(marginalized<1e-4, marginalized)\n",
    "            count = len([i for i in marginalized if i > 1e-3])\n",
    "            #count up how many elements are in the row of R_AB --> if it is less than 6, don't measure it\n",
    "            #because it will cause an error when trying to fit a Gaussian, k = n+1\n",
    "            if count < 6:\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "                continue\n",
    "\n",
    "            if ma.is_masked(marginalized)==True:\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(np.min(marginalized))],20,np.mean(marginalized)])\n",
    "                append_value = popt[1]\n",
    "\n",
    "                \n",
    "\n",
    "            #sometimes, it is necessary to shift the xs because the peak is at 180, which is right at the cutoff\n",
    "            except RuntimeError or OptimizeError: \n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "\n",
    "                continue\n",
    "                \n",
    "\n",
    "\n",
    "                    \n",
    "            if (popt[0]>0):\n",
    "                try:\n",
    "                    popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(sorted(marginalized)[1])],20,np.mean(marginalized)])\n",
    "                    append_value = popt[1]\n",
    "                    if popt[0] > 0:\n",
    "\n",
    "\n",
    "                        theta_hat.append(0)\n",
    "                        theta_hat_e.append(0)\n",
    "\n",
    "                        continue\n",
    "\n",
    "\n",
    "                except RuntimeError or OptimizeError :\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "            if ((popt[1] - 3*np.sqrt(pcov[1][1])) < 0) or ((popt[1] + 3*np.sqrt(pcov[1][1])) > 180):\n",
    "                theta_list_shifted = theta_list+find_nearest(theta_list,90)\n",
    "                index_1 = list(theta_list).index(find_nearest(theta_list,90))\n",
    "                new_marginalized = np.concatenate((marginalized[index_1:], marginalized[:index_1]))\n",
    "\n",
    "                try:\n",
    "                    popt,pcov = curve_fit(gauss,theta_list_shifted,new_marginalized,p0=[-abs(np.min(new_marginalized)-np.max(new_marginalized)),theta_list_shifted[list(new_marginalized).index(np.min(new_marginalized))],20,np.mean(new_marginalized)])\n",
    "                    \n",
    "                    if popt[0] > 0:\n",
    "                        theta_hat.append(0)\n",
    "                        theta_hat_e.append(0)\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    \n",
    "                    if popt[1] > 180:\n",
    "                        append_value = popt[1]-180\n",
    "                    else:\n",
    "                        append_value = popt[1]\n",
    "\n",
    "                except RuntimeError or OptimizeError :\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "\n",
    "            theta_hat.append(append_value)\n",
    "            theta_hat_e.append(np.sqrt(pcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        delta_theta_sum=[]\n",
    "        delta_theta_sum_e=[]\n",
    "        \n",
    "        \n",
    "        for l in range(int(len(p_list)/2)):\n",
    "            if (theta_hat[0+l]==0) or (theta_hat[-1-l]==0) or (abs(theta_hat[0+l])>180) or (abs(theta_hat[-1-l]) > 180):\n",
    "                \n",
    "                delta_theta_sum.append(0)\n",
    "                delta_theta_sum_e.append(0)\n",
    "            else:\n",
    "                \n",
    "                \n",
    "                if abs(theta_hat[0+l]-theta_hat[-1-l]) > 90:\n",
    "                    #because the maximum you can be apart is 90\n",
    "                    inside = 180 - abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "                else:\n",
    "                    inside = abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "                \n",
    "                delta_theta_sum.append(inside)\n",
    "                delta_theta_sum_e.append(np.sqrt((theta_hat_e[0+l])**2+\n",
    "                                             (theta_hat_e[-1-l])**2))\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "        theta_hat_mask = ma.masked_where(theta_hat==0, theta_hat)\n",
    "        theta_hat_mask = ma.masked_where(abs(theta_hat_mask) >180, theta_hat_mask)\n",
    "        \n",
    "        theta_hat_list.append(theta_hat_mask)\n",
    "        theta_hat_e_list.append(theta_hat_e)\n",
    "        \n",
    "        delta_theta_sum_masked=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "\n",
    "        #A is weighted by the A value of the center of the map\n",
    "        A = ((ma.sum(delta_theta_sum)/(ma.count(delta_theta_sum_masked)**2)))*OG_weight\n",
    "       \n",
    "        A_percent_e = []\n",
    "        for l in range(len(delta_theta_sum_e)):\n",
    "            if delta_theta_sum[l] != 0 :\n",
    "                A_percent_e.append((delta_theta_sum_e[l])**2)\n",
    "        A_abs_error = np.sqrt(np.sum(A_percent_e))#so this is on the numerator of the A error only\n",
    "        A_error = (A_abs_error/ma.sum(delta_theta_sum))*A\n",
    "       \n",
    "        \n",
    "        \n",
    "        A_list.append(A)\n",
    "        \n",
    "        \n",
    "        A_e_list.append(A_error)\n",
    "\n",
    "        #Also calculates the other types of asymmetry:\n",
    "        #A_2\n",
    "        delta_theta_sum=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "        delta_theta_sum_e=ma.masked_where(np.array(delta_theta_sum_e)==0, delta_theta_sum_e)\n",
    "        \n",
    "        \n",
    "        A_2 = ma.sum(delta_theta_sum/delta_theta_sum_e)\n",
    "        \n",
    "        \n",
    "        \n",
    "        A_2_list.append(A_2)\n",
    "        \n",
    "        R_AB_list.append(R_AB_array)\n",
    "        \n",
    "    \n",
    "      \n",
    "    \n",
    "    \n",
    "    A_list = np.array(A_list)\n",
    "    A_list = ma.masked_where(np.isnan(A_list), A_list)\n",
    "    \n",
    "    A_list_array = np.reshape(np.array(A_list), (7,7))\n",
    "    A_e_list_array = np.reshape(np.array(A_e_list), (7,7))\n",
    "\n",
    "    \n",
    "    #first_number = 33-3*factor#33-3*factor = 27 if factor = 2\n",
    "    \n",
    "    #print('first number', first_number, factor)\n",
    "    first_number = X_list_real[0]\n",
    "    x = factor*np.linspace(0, np.shape(A_list_array)[0]-1,np.shape(A_list_array)[0])+first_number\n",
    "    #y = (factor*6-factor*np.linspace(0, np.shape(A_list_array)[1]-1, np.shape(A_list_array)[1]))+first_number\n",
    "    y = (factor*np.linspace(0, np.shape(A_list_array)[1]-1, np.shape(A_list_array)[1]))+first_number\n",
    "    \n",
    "    print('matching x and y with X and Y real', x, X_list_real)\n",
    "    \n",
    "    if min(X_list_real) != min(x):\n",
    "        #this is improper scaling\n",
    "        print('x and y', x, y)\n",
    "    \n",
    "        print('this is what it should match X_list', X_list_real, Y_list_real)\n",
    "    \n",
    "        STOP\n",
    "    \n",
    "    \n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ax0.imshow(A_list_array, cmap='plasma')\n",
    "    cs = ax0.contour(x,y, A_list_array, 5, colors='orange')#was 5\n",
    "    p = cs.levels#collections[0].get_paths()[0]\n",
    "    \n",
    "    if plot=='yes':\n",
    "        im1 = ax0.scatter(np.flip(Y_list_real, axis=0),X_list_real,c=A_list, s=30, zorder=100)\n",
    "\n",
    "        plt.colorbar(im0)\n",
    "        \n",
    "    #Now, snatch the last level and use it to blur everything else out and find the center\n",
    "    #now fill with zeros and do your best to turn into a binary bitmask'''\n",
    "    if trouble=='yes':\n",
    "        print(p[0], p)\n",
    "    ret,thresh = cv2.threshold(A_list_array,p[-1]/2,100,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    #ret, thresh = cv2.adaptiveThreshold(A_list_array, 50, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 115, 1)\n",
    "    M = cv2.moments(thresh)\n",
    "    \n",
    "    if trouble=='yes':\n",
    "        plt.clf()\n",
    "        plt.imshow(A_list_array)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        print('moments', M)\n",
    "        print('ret', ret)\n",
    "\n",
    "       \n",
    "    \n",
    "        plt.clf()\n",
    "        plt.imshow(thresh)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #transform to flip in the x coordinate around the center coordinate, which changes based on the factor\n",
    "    cX_flip = 6-cX\n",
    "    \n",
    "    x_match = cX_flip+first_number#33-3*factor\n",
    "    y_match = (cY)+first_number#33-3*factor\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if plot=='yes':\n",
    "        \n",
    "\n",
    "        print('this is the cX and cY', x_match, y_match)\n",
    "\n",
    "\n",
    "        plt.scatter( x_match, y_match, marker='x', color='red', zorder=105)\n",
    "        plt.axhline(y=np.shape(vel_field)[0]/2, color='red')\n",
    "        plt.axvline(x=np.shape(vel_field)[0]/2, color='red')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        plt.clf()\n",
    "        plt.imshow(thresh)\n",
    "        plt.scatter(cX,cY, marker='x', color='red')\n",
    "\n",
    "        x = np.linspace(0, np.shape(A_list_array)[0]-1,np.shape(A_list_array)[0])\n",
    "        y = (np.linspace(0, np.shape(A_list_array)[1]-1, np.shape(A_list_array)[1]))\n",
    "        x, y = np.meshgrid(x,y)\n",
    "\n",
    "        plt.contour(x,y, A_list_array, 5, colors='orange')#was 5\n",
    "        plt.xlim([6,0])\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''now find the min index of this'''\n",
    "    for ii in range(len(X_list)):\n",
    "        if X_list[ii]==find_nearest(np.array(X_list),x_match) and Y_list[ii]==find_nearest(np.array(np.flip(Y_list, axis=0)),y_match):\n",
    "            min_index = ii\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    if factor ==1:\n",
    "        if abs(box_list[min_index][0])>2 or abs(box_list[min_index][1])>2:\n",
    "            #then we are on the edge\n",
    "            expand=1\n",
    "        else:\n",
    "            expand=0\n",
    "    else:\n",
    "        if abs(box_list[min_index][0])>5 or abs(box_list[min_index][1])>5:\n",
    "            min_index=24\n",
    "        expand=0\n",
    "        \n",
    "    \n",
    "    \n",
    "    if plot=='yes':\n",
    "        plt.clf()\n",
    "        plt.imshow(R_AB_list[min_index], cmap='summer')\n",
    "        locs, labels = plt.yticks()\n",
    "        #p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5, int(np.shape(vel_field)[0]/2)-5,n_p)#was 20\n",
    "\n",
    "        ylabels = [p_list[0], 0, p_list[-1]]\n",
    "        ylocs = [locs[0], locs[-1]/2, locs[-1]] \n",
    "        plt.yticks(ylocs, ylabels)\n",
    "\n",
    "        locs, labels = plt.xticks()\n",
    "        #p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5, int(np.shape(vel_field)[0]/2)-5,n_p)#was 20\n",
    "\n",
    "        xlabels = [theta_list[0], theta_list[-1]/2, theta_list[-1]]\n",
    "        xlocs = [locs[0], locs[-1]/2, locs[-1]] \n",
    "        plt.xticks(xlocs, xlabels)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "   \n",
    "    return box_list[min_index],R_AB_list[min_index], A_list[min_index],  A_2_list[min_index],p_list, theta_list, theta_hat_list[min_index], theta_hat_e_list[min_index], expand\n",
    "\n",
    "def input_kinemetry(plateid, x_list_after, y_list_after, vel_list_after, vel_e_list_after, sig_list_after, sig_e_list_after,  img_x, img_y,  plot, size):\n",
    "    \"\"\"\n",
    "    Creates an input file for kinemetry (.txt file) that has columns of x and y coords, velocity, velocity dispersion,\n",
    "    and the errors on both of these values.\n",
    "    \"\"\"\n",
    "    file2=open('kinemetry_input_txt/kinemetry_input_'+str(plateid)+'.txt','w')\n",
    "    file2.write('#'+'\\t'+'XBIN'+'\\t'+'YBIN'+'\\t'+'VEL'+'\\t'+'ER_VEL'+'\\t'+'SIG'+'\\t'+'ER_SIG'+'\\n')\n",
    "    \n",
    "    #These are the coordinates of the kinematic center of the galaxy\n",
    "    middle_x=img_x\n",
    "    middle_y=img_y\n",
    "    \n",
    "    #for some reason, kinemetry wants each row indexed\n",
    "    counter=1\n",
    "    \n",
    "    for i in range(len(x_list_after)):\n",
    "        if np.isnan(vel_list_after[i]):#mask these values by not including them in the file\n",
    "            #file2.write(str(counter)+'\\t'+str((middle_x-x_list_after[len(x_list_after)-1-i]))+'\\t'+str((middle_y-y_list_after[len(x_list_after)-1-i]))+'\\t')\n",
    "            #file2.write('--'+'\\t'+'--'+'\\t'+'--'+'\\t'+'--'+'\\n')\n",
    "        \n",
    "            continue\n",
    "        if vel_e_list_after[i]==0.0:#these are also list indices to mask\n",
    "            #file2.write(str(counter)+'\\t'+str((middle_x-x_list_after[len(x_list_after)-1-i]))+'\\t'+str((middle_y-y_list_after[len(x_list_after)-1-i]))+'\\t')\n",
    "            #file2.write('--'+'\\t'+'--'+'\\t'+'--'+'\\t'+'--'+'\\n')\n",
    "        \n",
    "            continue\n",
    "        file2.write(str(counter)+'\\t'+str((middle_x-x_list_after[len(x_list_after)-1-i]))+'\\t'+str((middle_y-y_list_after[len(x_list_after)-1-i]))+'\\t')\n",
    "        file2.write(str(vel_list_after[i])+'\\t'+str(vel_e_list_after[i])+'\\t'+str(sig_list_after[i])+'\\t'+str(sig_e_list_after[i])+'\\n')\n",
    "        counter +=1\n",
    "\n",
    "    file2.close()\n",
    "    \n",
    "    #optional, you can plot it to check\n",
    "    if plot=='yes':\n",
    "        file_check='kinemetry_input_txt/kinemetry_input_'+str(plateid)+'.txt'\n",
    "        stel_vel=np.zeros((size,size))\n",
    "    \n",
    "        with open(file_check, 'r') as f:\n",
    "            data = f.readlines()\n",
    "\n",
    "\n",
    "            x_list=[]\n",
    "            y_list=[]\n",
    "            vel_list=[]\n",
    "            \n",
    "\n",
    "            for line in data:\n",
    "                words = line.split()\n",
    "                #print('words', words)\n",
    "\n",
    "                if words[1]=='XBIN':\n",
    "                    continue\n",
    "                else:\n",
    "                    x_list.append(float(words[1]))\n",
    "                    y_list.append(float(words[2]))\n",
    "                    vel_list.append(float(words[3]))\n",
    "                    \n",
    "                    stel_vel[int(float(words[1])-size/2),int(float(words[2])-size/2)] = float(words[3])\n",
    "                    \n",
    "        plt.clf()\n",
    "        im0=plt.imshow(stel_vel, cmap='RdBu_r')\n",
    "        plt.scatter(np.shape(stel_vel)[0]/2, np.shape(stel_vel)[1]/2, color='red', marker='x')\n",
    "        plt.axhline(y=np.shape(stel_vel)[0]/2, color='red')\n",
    "        plt.axvline(x=np.shape(stel_vel)[0]/2, color='red')\n",
    "    \n",
    "        plt.colorbar(im0)\n",
    "        plt.show()\n",
    "print('compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
